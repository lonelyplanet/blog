<?xml version="1.0" encoding="UTF-8"?>
<!--
 This is a WordPress eXtended RSS file generated by WordPress as an export of your site.
 It contains information about your site's posts, pages, comments, categories, and other content.
 You may use this file to transfer that content from one site to another.
 This file is not intended to serve as a complete backup of your site.

 To import this information into a WordPress site follow these steps:
 1. Log in to that site as an administrator.
 2. Go to Tools: Import in the WordPress admin panel.
 3. Install the "WordPress" importer from the list.
 4. Activate & Run Importer.
 5. Upload this file using the form provided on that page.
 6. You will first be asked to map the authors in this export file to users
    on the site. For each author, you may choose to map to an
    existing user on the site or to create a new user.
 7. WordPress will then import each of the posts, pages, comments, categories, etc.
    contained in this file into your site.
-->
<!-- generator="WordPress.com" created="2013-10-14 11:39"-->
<rss version="2.0" xmlns:excerpt="http://wordpress.org/export/1.2/excerpt/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:wfw="http://wellformedweb.org/CommentAPI/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:wp="http://wordpress.org/export/1.2/">
  <channel>
<title>Lonely Planet Engineering Blog</title>
<link>http://engineering.lonelyplanet.com</link>
<description>devops, software engineering, performance, being awesome</description>
<pubDate>Mon, 14 Oct 2013 11:39:38 +0000</pubDate>
<language>en</language>
<wp:wxr_version>1.2</wp:wxr_version>
<wp:base_site_url>http://wordpress.com/</wp:base_site_url>
<wp:base_blog_url>http://engineering.lonelyplanet.com</wp:base_blog_url>
<wp:wp_author>
  <wp:author_login>lpengineering</wp:author_login>
  <wp:author_email>engineering@lonelyplanet.com</wp:author_email>
  <wp:author_display_name><![CDATA[lpengineering]]></wp:author_display_name>
  <wp:author_first_name><![CDATA[]]></wp:author_first_name>
  <wp:author_last_name><![CDATA[]]></wp:author_last_name>
</wp:wp_author>
<wp:wp_author>
  <wp:author_login>amandaskipper</wp:author_login>
  <wp:author_email>amanda.skipper@lonelyplanet.com</wp:author_email>
  <wp:author_display_name><![CDATA[amandaskipper]]></wp:author_display_name>
  <wp:author_first_name><![CDATA[]]></wp:author_first_name>
  <wp:author_last_name><![CDATA[]]></wp:author_last_name>
</wp:wp_author>
<wp:wp_author>
  <wp:author_login>mjenno</wp:author_login>
  <wp:author_email>mark.jennings@lonelyplanet.com</wp:author_email>
  <wp:author_display_name><![CDATA[mjenno]]></wp:author_display_name>
  <wp:author_first_name><![CDATA[]]></wp:author_first_name>
  <wp:author_last_name><![CDATA[]]></wp:author_last_name>
</wp:wp_author>
<wp:wp_author>
  <wp:author_login>julienberard</wp:author_login>
  <wp:author_email>julien.berard@lonelyplanet.com</wp:author_email>
  <wp:author_display_name><![CDATA[julienberard]]></wp:author_display_name>
  <wp:author_first_name><![CDATA[]]></wp:author_first_name>
  <wp:author_last_name><![CDATA[]]></wp:author_last_name>
</wp:wp_author>
<wp:wp_author>
  <wp:author_login>dpdnolan</wp:author_login>
  <wp:author_email>dpdnolan@gmail.com</wp:author_email>
  <wp:author_display_name><![CDATA[dpdnolan]]></wp:author_display_name>
  <wp:author_first_name><![CDATA[]]></wp:author_first_name>
  <wp:author_last_name><![CDATA[]]></wp:author_last_name>
</wp:wp_author>
<wp:wp_author>
  <wp:author_login>marckysharky</wp:author_login>
  <wp:author_email>marcky.sharky@googlemail.com</wp:author_email>
  <wp:author_display_name><![CDATA[marckysharky]]></wp:author_display_name>
  <wp:author_first_name><![CDATA[]]></wp:author_first_name>
  <wp:author_last_name><![CDATA[]]></wp:author_last_name>
</wp:wp_author>
<wp:wp_author>
  <wp:author_login>mbarger00</wp:author_login>
  <wp:author_email>barger.mark@gmail.com</wp:author_email>
  <wp:author_display_name><![CDATA[mbarger]]></wp:author_display_name>
  <wp:author_first_name><![CDATA[]]></wp:author_first_name>
  <wp:author_last_name><![CDATA[]]></wp:author_last_name>
</wp:wp_author>
<wp:wp_author>
  <wp:author_login>mriddlelp</wp:author_login>
  <wp:author_email>matthew.riddle@lonelyplanet.com.au</wp:author_email>
  <wp:author_display_name><![CDATA[mriddlelp]]></wp:author_display_name>
  <wp:author_first_name><![CDATA[]]></wp:author_first_name>
  <wp:author_last_name><![CDATA[]]></wp:author_last_name>
</wp:wp_author>
<generator>http://wordpress.com/</generator>
<image>
		<url>https://s2.wp.com/i/buttonw-com.png</url>
		<title>Lonely Planet Engineering Blog</title>
		<link>http://engineering.lonelyplanet.com</link>
	</image>
	<item>
  <title>Rails and Sass Error on First Request in Production</title>
  <link>http://engineering.lonelyplanet.com/2012/12/09/rails-and-sass-error-on-first-request-in-production/</link>
  <pubDate>Sun, 09 Dec 2012 12:03:29 +0000</pubDate>
  <dc:creator>mjenno</dc:creator>
  <guid isPermaLink="false">http://engineering.lonelyplanet.com/?p=9</guid>
  <description/>
  <content:encoded><![CDATA[<div>

Simple issue, but something we bumped into. If you just want the answer please skip straight to The Fix
<h3>The stack:</h3>
<ul>
	<li>Rails 3 application</li>
	<li>Nginx</li>
	<li>Unicorn</li>
	<li>Rails engine for majority of UI codebase</li>
	<li>Sass</li>
	<li>HAML</li>
</ul>
<h3>Issue behaviour:</h3>
<ol>
	<li>Deployment of application via Chef</li>
	<li>Code checkout and symlink on completion</li>
	<li>Asset precompilation</li>
	<li>Unicorn restart</li>
	<li>First request to application via brower shows error</li>
</ol>
<h3>Logs:</h3>
<code>Sass::SyntaxError (File to import not found or unreadable: colours. Load paths: /opt/apps/app/releases/20120503122043/public/stylesheets/sass /opt/apps/app/releases/20120503122043/app/assets/stylesheets): /app/assets/stylesheets/application.sass:1</code>

The question that struck was why Sass was even looking/amending these files, even though we have already precompiled the assets?

The answer lies in the <a href="http://sass-lang.com/docs/yardoc/Sass/Plugin.html">Sass Plugin</a>, which "provides global options and checks whether CSS files need to be updated."
<h3>The Fix</h3>
When using Rails engines to define Sass files which you want to import in your stylesheet manifest, make sure you add the following to your engine initializer:

<code>Sass::Plugin.add_template_location File.join(Gem.loaded_specs['{my_gem_name}'].full_gem_path, '/app/assets/stylesheets')</code>

This will ensure that when the Sass Plugin checks for updates on the stylesheet files when the application is restarted, and it processes the <code>@import</code> directive, it searches for the filename within your main application asset path, and your engine's asset path. e.g.

<code>@import 'colours'</code>

</div>
<footer><section id="statistics">Posted
<h1>by <a href="http://posterous.com/users/YCa5xfrcfjr" rel="author">Marc Watts</a></h1>
</section></footer>]]></content:encoded>
  <excerpt:encoded><![CDATA[]]></excerpt:encoded>
  <wp:post_id>9</wp:post_id>
  <wp:post_date>2012-12-09 12:03:29</wp:post_date>
  <wp:post_date_gmt>2012-12-09 12:03:29</wp:post_date_gmt>
  <wp:comment_status>open</wp:comment_status>
  <wp:ping_status>open</wp:ping_status>
  <wp:post_name>rails-and-sass-error-on-first-request-in-production</wp:post_name>
  <wp:status>publish</wp:status>
  <wp:post_parent>0</wp:post_parent>
  <wp:menu_order>0</wp:menu_order>
  <wp:post_type>post</wp:post_type>
  <wp:post_password/>
  <wp:is_sticky>0</wp:is_sticky>
  <category domain="post_tag" nicename="nicorn"><![CDATA[nicorn]]></category>
  <category domain="post_tag" nicename="production"><![CDATA[production]]></category>
  <category domain="post_tag" nicename="rails"><![CDATA[rails]]></category>
  <category domain="post_tag" nicename="ruby"><![CDATA[ruby]]></category>
  <category domain="post_tag" nicename="sass"><![CDATA[sass]]></category>
  <category domain="category" nicename="uncategorized"><![CDATA[Uncategorized]]></category>
  <category domain="post_tag" nicename="unicorn"><![CDATA[unicorn]]></category>
  <wp:postmeta>
    <wp:meta_key>_publicize_pending</wp:meta_key>
    <wp:meta_value><![CDATA[1]]></wp:meta_value>
  </wp:postmeta>
  <wp:postmeta>
    <wp:meta_key>_elasticsearch_indexed_on</wp:meta_key>
    <wp:meta_value><![CDATA[2012-12-09 12:03:29]]></wp:meta_value>
  </wp:postmeta>
</item>
<item>
  <title>Monitoring our applications - Ruby - Overview</title>
  <link>http://engineering.lonelyplanet.com/2012/12/09/monitoring-our-applications-ruby-overview/</link>
  <pubDate>Sun, 09 Dec 2012 12:05:31 +0000</pubDate>
  <dc:creator>mjenno</dc:creator>
  <guid isPermaLink="false">http://engineering.lonelyplanet.com/?p=13</guid>
  <description/>
  <content:encoded><![CDATA[A target of ours has been to improve the monitoring of our applications. I'm sure this is true for nearly all Software companies. We have applications written in various languages, the main "must-monitor" ones in Ruby and Java. This article explains how we implemented <a href="http://codeascraft.etsy.com/2011/02/15/measure-anything-measure-everything/">statsd</a> into our Ruby applications.
<h3>Requirements:</h3>
<ul>
	<li>Simple to setup</li>
	<li>Clean implementation</li>
	<li>Easy to change</li>
	<li>Open source (bonus)</li>
</ul>
We started with the quick and simple <a href="https://github.com/reinh/statsd">reinh statsd</a> implementation, but quickly found we wanted more functionality, such as:
<ul>
	<li>Automatically prefix the application name for the statistic being sent</li>
	<li>Automatically prefix the server name for the statistic being sent</li>
	<li>Automatically prefix the environment name for the statistic being sent</li>
	<li>Configure via YAML file and Ruby code</li>
	<li>Less inline code interference</li>
</ul>
At this point <a href="https://github.com/lonelyplanet/fozzie">Fozzie</a> was born. <a href="https://github.com/lonelyplanet/fozzie">Fozzie</a> rapidly grew in functionality as we learnt what we wanted to measure in our Ruby and Ruby on Rails applications. The simplicity of statsd allowed us to really extend what we wanted to measure, and also abstract the amount of code needed to achieve this.
<h3>YAML Based Configuration</h3>
Fozzie settings can be customised via a fozzie.yml file, located at config/ on your application root.

You can set the host, port, appname, and namespaces for your application.

Namespaces are the class calls you want to use in your code to register statistics. The defaults are:

<code>Stats.increment 'wat'</code>

<code>S.increment 'wat'</code>

<code>Statistics.increment 'wat'</code>

<code>Warehouse.increment 'wat'</code>
<h3>Ruby Code Monitoring</h3>
To monitor some Ruby code Fozzie provided namespace to register your stats against, such as:

<code>S.increment 'wat'</code>

<code>S.decrement 'wat'</code>

<code>S.time_for 'wat' { sleep 5 }</code>

<code>S.timing, 'wat', 500</code>

<code>S.time_to_do { sleep 5 }</code>
<h3>Rack Middleware</h3>
Fozzie allows Rack developers to measure their controller action methods with minimum effort.

<code>require 'rack'</code>

<code>require 'fozzie'</code>

<code>app = Rack::Builder.new { use Fozzie::Rack::Middleware lambda { |env| [200, {'Content-Type' =&gt; 'text/plain'}, 'OK'] } }</code>
<h3>Rails Middleware</h3>
Base upon the Rack middleware, Fozzie can provide statistics of the Rails controller action timings. If Fozzie is added to the Rails application Gemfile, the Fozzie Railtie will automatically load the Rails Middleware into the application stack on application initialization.
<h3>Further Reading</h3>
More blog posts will be coming on more functionality we have enabled in Fozzie, but if you just want the code here are the links:

<a href="https://github.com/lonelyplanet/fozzie">Fozzie on Github</a>

<a href="http://rubygems.org/gems/fozzie">Fozzie on Rubygems</a>]]></content:encoded>
  <excerpt:encoded><![CDATA[]]></excerpt:encoded>
  <wp:post_id>13</wp:post_id>
  <wp:post_date>2012-12-09 12:05:31</wp:post_date>
  <wp:post_date_gmt>2012-12-09 12:05:31</wp:post_date_gmt>
  <wp:comment_status>open</wp:comment_status>
  <wp:ping_status>open</wp:ping_status>
  <wp:post_name>monitoring-our-applications-ruby-overview</wp:post_name>
  <wp:status>publish</wp:status>
  <wp:post_parent>0</wp:post_parent>
  <wp:menu_order>0</wp:menu_order>
  <wp:post_type>post</wp:post_type>
  <wp:post_password/>
  <wp:is_sticky>0</wp:is_sticky>
  <category domain="category" nicename="uncategorized"><![CDATA[Uncategorized]]></category>
  <wp:postmeta>
    <wp:meta_key>_publicize_pending</wp:meta_key>
    <wp:meta_value><![CDATA[1]]></wp:meta_value>
  </wp:postmeta>
  <wp:postmeta>
    <wp:meta_key>_elasticsearch_indexed_on</wp:meta_key>
    <wp:meta_value><![CDATA[2012-12-09 12:05:31]]></wp:meta_value>
  </wp:postmeta>
</item>
<item>
  <title>Monitoring our applications - Ruby - Methods</title>
  <link>http://engineering.lonelyplanet.com/2012/12/09/monitoring-our-applications-ruby-methods/</link>
  <pubDate>Sun, 09 Dec 2012 12:06:27 +0000</pubDate>
  <dc:creator>mjenno</dc:creator>
  <guid isPermaLink="false">http://engineering.lonelyplanet.com/?p=16</guid>
  <description/>
  <content:encoded><![CDATA[<div>

Fozzie was good, and we were happy with progress. We were monitoring applications in real time, the code was looking ok, and the stats looked good on the big screens.

On reflection of the code though, we felt there was room for improvement on the way in which were were referencing Fozzie for the timing of code. We saw a constant pattern of:

<code>def foo</code> <code> </code>

<code>  S.time_to_do ["class", "foo"] do </code> <code>   </code>

<code>    # bla bla bla</code> <code> </code>

<code>  end</code>

<code>end</code>

We felt this would be a massive improvement on this scenario:

<code>_monitor</code>

<code>def foo</code>

<code>  # bla bla bla</code> <code> </code>

<code>end</code>
<h3>Requirements</h3>
In order to achieve this we needed to:
<ul>
	<li>Dynamically detect methods being added to classes</li>
	<li>Alias the method to allow us to automatically wrap our Fozzie code around the original</li>
</ul>
<h3>Method Added and Singleton Method Added</h3>
Ruby supplies a callback for instance and class method declarations; method_added and singleton_method_added.

Because we wanted/needed to be choosy about which methods to measure, we wanted a flag to indicate when a method should be processed. To achieve this we implemented our _monitor dsl method, as follows:

<code>def _monitor</code>

<code>  @_monitor_method_flag = true</code>

<code>end</code>

And reference the <code>@_monitor_method_flag</code> class instance method in our <code>method_added</code> and<code>singleton_method_added</code> methods.
<h3>Method Aliasing</h3>
Once we had the name of the method we wanted to monitor, and we knew it has been created on the Class, we wanted to alias it.

Aliasing enables Fozzie to wrap it's timing logic around the original method. Ruby facets provides a nice<code>alias_method_chain</code> that we can use to achieve this.

To alias an instance method we can simply call:

<code>self.alias_method_chain 'foo', 'monitor'</code>

To alias a class methods we need to be slightly smarter:

<code>self.singleton_class.class_eval { alias_method_chain 'foo', 'monitor' }</code>

The alias_method_chain gives us

<code>alias_method :foo_without_monitor, :foo</code>

<code>alias_method :foo, :foo_with_monitor</code>

allowing us to access the original method.
<h3>Putting It All Together</h3>
Once these elements had been worked out it was all down to tying the pieces together and constructing a neat implementation.

To enable the <code>_monitor</code> method to be referenced in any class, we need to include it into the Ruby <a href="https://github.com/lonelyplanet/fozzie/blob/master/lib/core_ext/module/monitor.rb">Module</a> class, which is required within the main <a href="https://github.com/lonelyplanet/fozzie/blob/master/lib/fozzie.rb">Fozzie</a> class.

<code>class Module</code>

<code>  def _monitor</code>

<code>    # Our code...</code>

<code>  end</code>

<code>end</code>

This extension includes <a href="https://github.com/lonelyplanet/fozzie/blob/master/lib/fozzie/sniff.rb">Fozzie::Sniff</a> into the class, and this then extends the class with the <a href="https://github.com/lonelyplanet/fozzie/blob/master/lib/fozzie/sniff.rb">Fozzie::Sniff::ClassMethods</a> to tie together all our nitty-gritty aliasing, etc.

</div>
<footer><section id="statistics">Posted
<h1>by <a href="http://posterous.com/users/YCa5xfrcfjr" rel="author">Marc Watts</a></h1>
</section></footer>]]></content:encoded>
  <excerpt:encoded><![CDATA[]]></excerpt:encoded>
  <wp:post_id>16</wp:post_id>
  <wp:post_date>2012-12-09 12:06:27</wp:post_date>
  <wp:post_date_gmt>2012-12-09 12:06:27</wp:post_date_gmt>
  <wp:comment_status>open</wp:comment_status>
  <wp:ping_status>open</wp:ping_status>
  <wp:post_name>monitoring-our-applications-ruby-methods</wp:post_name>
  <wp:status>publish</wp:status>
  <wp:post_parent>0</wp:post_parent>
  <wp:menu_order>0</wp:menu_order>
  <wp:post_type>post</wp:post_type>
  <wp:post_password/>
  <wp:is_sticky>0</wp:is_sticky>
  <category domain="category" nicename="uncategorized"><![CDATA[Uncategorized]]></category>
  <wp:postmeta>
    <wp:meta_key>_publicize_pending</wp:meta_key>
    <wp:meta_value><![CDATA[1]]></wp:meta_value>
  </wp:postmeta>
  <wp:postmeta>
    <wp:meta_key>_elasticsearch_indexed_on</wp:meta_key>
    <wp:meta_value><![CDATA[2012-12-09 12:06:27]]></wp:meta_value>
  </wp:postmeta>
</item>
<item>
  <title>Object Oriented Sass</title>
  <link>http://engineering.lonelyplanet.com/2012/12/09/object-oriented-sass/</link>
  <pubDate>Sun, 09 Dec 2012 12:07:12 +0000</pubDate>
  <dc:creator>mjenno</dc:creator>
  <guid isPermaLink="false">http://engineering.lonelyplanet.com/?p=19</guid>
  <description/>
  <content:encoded><![CDATA[I’ve been re-examining how we declare and manage CSS objects at LP, recently using the placeholder syntax (%) in Sass over a class. I had a couple of reservations around this, partly because it’s a leap away from the traditional OOCSS method of using multiple classes as building blocks but also in its usability and impact on performance.

The more I’ve been dabbling with the placeholder approach though; the more I can see that traversing the middle ground between the two is going to result in suboptimal code. So I decided to do some research and disprove my reservations.

For those who haven't yet used them, selectors with placeholders will not be included in the CSS output but they are able to be extended. For example:
<div>
<div>
<pre>%some-unused-class
  color: red
  background: black

%base-button-class
  padding: 10px
  display: inline-block

.checkout-button
  @extend %base-button-class
  background-color: red

.submit-button
  @extend %base-button-class
  background-color: black</pre>
</div>
</div>
will output to:
<div>
<div>
<pre>.checkout-button,
.submit-button {
  padding: 10px;
  display: inline-block;
}

.checkout-button {
  background-color: red;
}
.submit-button {
  background-color: black;
}</pre>
</div>
</div>
And an example using everyone’s favourite media object would mean we no longer have to chain the .media class to benefit from its abstraction:
<div>
<div>
<pre>%media
  … the media object …

.comment-block
  @extend %media</pre>
</div>
</div>
Effectively what this allows us to do is construct our css objects <em>in</em> our css as opposed to in the markup. There are definitely pros and cons to this approach and all could be subjective depending on your existing codebase and workflow. I've highlighted some below but I'd be keen to hear of any that I have missed.
<h2>Let’s compare the two from a maintainability standpoint.</h2>
<table>
<tbody>
<tr>
<th>OOCSS</th>
<th>OOSass</th>
</tr>
<tr>
<td>Styles are defined by the markup</td>
<td>Styles are solely defined in the Sass</td>
</tr>
<tr>
<td>Simpler, all declarations are available for use in the dom</td>
<td>Only some style declarations are exposed</td>
</tr>
<tr>
<td>Potentially leaner stylesheet</td>
<td>Leaner markup</td>
</tr>
</tbody>
</table>
<h3>OOSass pros and cons:</h3>
<h4>Pros</h4>
<ul>
	<li>More readable style declarations - there’s no need to keep your naming short</li>
	<li>Leaner markup</li>
	<li>More selective use of styles (only really applicable to sites with multiple stylesheets responsible for different areas)</li>
</ul>
<h4>Cons - all debatable</h4>
<ul>
	<li>Back end devs have to write Sass if they want to build up styles</li>
	<li>Slower to iterate on styles than directly on the dom</li>
	<li>Only possible using preprocessors</li>
</ul>
<h4>Questionables (makes sense to me but is it actually a Pro?)</h4>
<ul>
	<li>OO happens within the CSS</li>
</ul>
<h2>Performance</h2>
If you’re working with OOCSS chances are you care about performance and metrics. So, whilst the placeholder syntax is feeling like a nice approach to me, I wanted to run some tests to see the effect on css size.

I took the css for <a href="http://ianfeather.co.uk/">ianfeather.co.uk</a> as the base file. It was written a long time ago with loose OOCSS and is fairly performant but not heavily optimised.

Following this, I optimised the CSS by abstracting out some classes and thinning down a few selectors. I wasn’t expecting big improvements but I wanted to ensure that I had a performant baseline file to test against.

My main concern was that the gzipped file size would actually increase because of less repetition in the code so it was good to see that this is minimal and that the final code is still smaller. (This blocker could potentially be removed only by extending placeholders which have at least two rule declarations inside.)
<table>
<tbody>
<tr>
<th></th>
<th>File size</th>
<th>When Gzipped</th>
<th>Compression rate</th>
</tr>
<tr>
<td>Base</td>
<td>26514</td>
<td>7055</td>
<td>73%</td>
</tr>
<tr>
<td>After optimisation</td>
<td>26411</td>
<td>6196</td>
<td>77%</td>
</tr>
<tr>
<td>Using OOSass</td>
<td>24520</td>
<td>5920</td>
<td>76%</td>
</tr>
</tbody>
</table>
<h2>Performance in the browser</h2>
The CSS file size is key to the critical path but I also wanted to ensure that using this method wouldn’t increase the selector matching or paint time.

I created two pages, each with 1200 buttons, one using chained classes and one using extended classes. I then profiled them using Opera’s CSS Profiler. Unfortunately the results were absolutely identical so this test was inconclusive. Perhaps a larger test file with more variance would be required to create a true test.

The Profiled results for both pages:

&nbsp;
<div><img alt="Opera-profile" src="http://getfile3.posterous.com/getfile/files.posterous.com/temp-2012-07-30/gqljjyuevtomeeyHxwFoHctuaqjfAHBqCcuqEcufskGgoioubHnEzukhoqqe/opera-profile.jpg.scaled699.jpg" height="167" width="442" /></div>
&nbsp;
<h2>Conclusions</h2>
Whilst our test showed there was no huge performance benefit for this approach, it also failed to show a<strong>downside</strong> for it. This, for me, is a validation of the approach and allows us to look at the more intangible benefits we outlined earlier.

I also think there are performance gains to be made when scaling up. We’ll use our Sass gem, Beaker, across a fairly wide range of projects and using this will mean each project has access to all objects and base classes as well as the ability to pick and choose which are required and which will be output to their project.css file.

Whether or not this approach is right for you is likely dependant on your existing css architecture. For us, we have the opportunity to shape our future CSS and I think this is a healthy way of doing it.]]></content:encoded>
  <excerpt:encoded><![CDATA[]]></excerpt:encoded>
  <wp:post_id>19</wp:post_id>
  <wp:post_date>2012-12-09 12:07:12</wp:post_date>
  <wp:post_date_gmt>2012-12-09 12:07:12</wp:post_date_gmt>
  <wp:comment_status>open</wp:comment_status>
  <wp:ping_status>open</wp:ping_status>
  <wp:post_name>object-oriented-sass</wp:post_name>
  <wp:status>publish</wp:status>
  <wp:post_parent>0</wp:post_parent>
  <wp:menu_order>0</wp:menu_order>
  <wp:post_type>post</wp:post_type>
  <wp:post_password/>
  <wp:is_sticky>0</wp:is_sticky>
  <category domain="category" nicename="uncategorized"><![CDATA[Uncategorized]]></category>
  <wp:postmeta>
    <wp:meta_key>_publicize_pending</wp:meta_key>
    <wp:meta_value><![CDATA[1]]></wp:meta_value>
  </wp:postmeta>
  <wp:postmeta>
    <wp:meta_key>_elasticsearch_indexed_on</wp:meta_key>
    <wp:meta_value><![CDATA[2012-12-09 12:07:12]]></wp:meta_value>
  </wp:postmeta>
</item>
<item>
  <title>A History of Web Performance @ Lonely Planet</title>
  <link>http://engineering.lonelyplanet.com/2012/12/09/a-history-of-web-performance-lonely-planet/</link>
  <pubDate>Sun, 09 Dec 2012 12:07:43 +0000</pubDate>
  <dc:creator>mjenno</dc:creator>
  <guid isPermaLink="false">http://engineering.lonelyplanet.com/?p=22</guid>
  <description/>
  <content:encoded><![CDATA[‘Screamingly fast’ is now a requirement of all our projects. We’ve only made incremental improvements to our page performance over the past couple of years but this is about to change dramatically. I’ll be sharing our progress on this blog. We’re also experimenting with tools to help us capture performance data in real time and we’ll share some of this data when we can.

If you’re in London and want to know more about what we’re doing at Lonely Planet, we’re presenting at the London Web Performance Meetup on <a href="http://www.meetup.com/London-Web-Performance-Group/events/69285112/" target="_blank">Metrics Driven Engineering</a>. Come down and check us out, we’d love to see you!

<strong>Turn the clock back 2 years…</strong>

Web performance became a hot topic at LP when our then Director of IT, <a href="http://linkd.in/MZ6dZI" target="_blank">Ed Cortis</a>, returned from Velocity 2010 a changed man. Ed made web performance a focus at Lonely Planet and is largely responsible for my passion. Soon after Ed's return, graphs like the one below were being hotly discussed around the office in Melbourne.

&nbsp;
<div><img alt="Conversion" src="http://getfile4.posterous.com/getfile/files.posterous.com/temp-2012-08-06/hzgvrlfjmEqIkdpxnGsujxoBmqEbnjonEkFsmwJqHgbEcpkqkvazysCHklGc/conversion.jpeg.scaled699.jpg" height="313" width="500" /></div>
&nbsp;

(From an <a href="http://bit.ly/PAnjaO" target="_blank">excellent piece</a> written by Josh Bixby of Strangeloop)

If our site adhered to Joshua’s model, this graph showed us that Lonely Planet was potentially losing 40% of our conversions due to poor page performance.

Many believed the delays were caused by third party content and that’s where improvements were needed. This presented a challenge to business owners as it meant changing revenue generating features.

My favourite suggestion for performance improvement was removing some ads to speed up the page and calculating whether the net increase in conversion made up for the loss in ad revenue. This was a bit too radical for our tastes.

We ran an A/B test asynchronously loading some ads in iFrames. But <a href="http://en.wikipedia.org/wiki/Lazy_loading" target="_blank">lazy loading</a> some ads on non-eCommerce areas of the site did not make much difference to conversion. We had designed a poor proof of concept.
<div>

Page speed was never viewed as a feature, rather as <a href="http://en.wikipedia.org/wiki/Technical_debt" target="_blank">technical debt</a>. Presented with a choice of developing new features or improving page performance, new features were always made a priority. It was extremely difficult to make improvements.

<strong>Fast forward to today…</strong>

In the past 12 months, we’ve been busy moving our online operations from Melbourne to London. But now that we’re up and running, the importance of web performance is back in a big way. New team, new focus and we’ve learnt from our previous endeavours.

We’ve recently completed a series of experiments on driving traffic to eCommerce areas of our site. The blue line below depicts the success of various experiments. The orange line is the control. The only difference between the big dip in experiment E and surrounding weeks D &amp; F is that we intentionally slowed down the user experience.

&nbsp;
<div><a href="http://devops.lonelyplanet.com/?page=1#"><img id="mainImage" alt="" src="http://getfile1.posterous.com/getfile/files.posterous.com/temp-2012-08-06/bzvJHGpCIelmtgsJwrrJtJcckphkJipmBEbnGugFfBlldpcgyuGcmpHhmjJt/Experiments.png.scaled699.png" height="251" width="699" /></a></div>
&nbsp;

There it was staring us in the face – the first hard evidence from <strong>our own site</strong> that page performance has a significant impact. Hardly a shock, but the magnitude of impact on our own users was now clear and undeniable.

My next blog post will benchmark our current performance. If you have any questions post them in the comments or email: engineering @ lonelyplanet.com.

Finally, don’t forget to check out our presentation on <a href="http://www.meetup.com/London-Web-Performance-Group/events/69285112/" target="_blank">Metrics Driven Engineering</a> at the London Web Performance Meetup. If you’re not in London I’ll catch you up on what happens in another blog post. Stay tuned!

</div>]]></content:encoded>
  <excerpt:encoded><![CDATA[]]></excerpt:encoded>
  <wp:post_id>22</wp:post_id>
  <wp:post_date>2012-12-09 12:07:43</wp:post_date>
  <wp:post_date_gmt>2012-12-09 12:07:43</wp:post_date_gmt>
  <wp:comment_status>open</wp:comment_status>
  <wp:ping_status>open</wp:ping_status>
  <wp:post_name>a-history-of-web-performance-lonely-planet</wp:post_name>
  <wp:status>publish</wp:status>
  <wp:post_parent>0</wp:post_parent>
  <wp:menu_order>0</wp:menu_order>
  <wp:post_type>post</wp:post_type>
  <wp:post_password/>
  <wp:is_sticky>0</wp:is_sticky>
  <category domain="category" nicename="uncategorized"><![CDATA[Uncategorized]]></category>
  <wp:postmeta>
    <wp:meta_key>_publicize_pending</wp:meta_key>
    <wp:meta_value><![CDATA[1]]></wp:meta_value>
  </wp:postmeta>
  <wp:postmeta>
    <wp:meta_key>_elasticsearch_indexed_on</wp:meta_key>
    <wp:meta_value><![CDATA[2012-12-09 12:07:43]]></wp:meta_value>
  </wp:postmeta>
</item>
<item>
  <title>How to get a job with our Engineering team</title>
  <link>http://engineering.lonelyplanet.com/2012/12/09/how-to-get-a-job-with-our-engineering-teams/</link>
  <pubDate>Sun, 09 Dec 2012 12:09:12 +0000</pubDate>
  <dc:creator>mjenno</dc:creator>
  <guid isPermaLink="false">http://engineering.lonelyplanet.com/?p=25</guid>
  <description/>
  <content:encoded><![CDATA[We're looking to hire enthusiastic, energetic and clever people. Are you great at Linux? AWS? Postgres? Ruby? MS SQL? A little of each, or a specialist in one field?

Send us a quick YouTube or Vimeo video telling us about yourself and what you're good at. Tell us a bit about:

1. What technology are you excited and passionate about?

2. What do you think is going to take off in the industry in the next year or 2?

3. Something entertaining (this one is completely optional).

Feel free to include anything else you like!

We're in London, so you'll need to be too.

We do accept standard CV's, but a video gives us a quick glimpse in to important things like cultural fit and communication qualities.]]></content:encoded>
  <excerpt:encoded><![CDATA[]]></excerpt:encoded>
  <wp:post_id>25</wp:post_id>
  <wp:post_date>2012-12-09 12:09:12</wp:post_date>
  <wp:post_date_gmt>2012-12-09 12:09:12</wp:post_date_gmt>
  <wp:comment_status>open</wp:comment_status>
  <wp:ping_status>open</wp:ping_status>
  <wp:post_name>how-to-get-a-job-with-our-engineering-teams</wp:post_name>
  <wp:status>publish</wp:status>
  <wp:post_parent>0</wp:post_parent>
  <wp:menu_order>0</wp:menu_order>
  <wp:post_type>post</wp:post_type>
  <wp:post_password/>
  <wp:is_sticky>0</wp:is_sticky>
  <category domain="category" nicename="uncategorized"><![CDATA[Uncategorized]]></category>
  <wp:postmeta>
    <wp:meta_key>_publicize_pending</wp:meta_key>
    <wp:meta_value><![CDATA[1]]></wp:meta_value>
  </wp:postmeta>
  <wp:postmeta>
    <wp:meta_key>_elasticsearch_indexed_on</wp:meta_key>
    <wp:meta_value><![CDATA[2012-12-09 12:09:12]]></wp:meta_value>
  </wp:postmeta>
</item>
<item>
  <title>lonelyplanet.com Performance Baseline</title>
  <link>http://engineering.lonelyplanet.com/2012/12/09/lonelyplanet-com-performance-baseline/</link>
  <pubDate>Sun, 09 Dec 2012 12:10:20 +0000</pubDate>
  <dc:creator>mjenno</dc:creator>
  <guid isPermaLink="false">http://engineering.lonelyplanet.com/?p=30</guid>
  <description/>
  <content:encoded><![CDATA[In our <a href="http://devops.lonelyplanet.com/a-history-of-web-performance-lonely-planet" target="_blank">first post</a> on site performance we promised to share some figures baselining our current performance. Since then, we’ve been preparing for <a href="http://velocityconf.com/velocityeu2012/public/schedule/detail/26634" target="_blank">our presentation at Velcoity EU</a> so it's taken longer than hoped to share these figures.

To baseline our performance, we’ve gathered figures for August on major areas of our site. These are full page load times using backbone tests in IE8 averaged across US, UK and Australia:

<strong>Homepage: 8.757</strong>

<strong>Forum: 4.236</strong>

<strong>Destination: 5.454</strong>

<strong>Shop homepage: 5.513</strong>

<strong>Shop details: 4.918</strong>

<strong>Things to do list: 5.671 </strong>

This list is far from exhaustive. From here, the most important thing we're doing is working on improving these numbers and expect to make great progress over the coming months.

We're also really excited about the tools we're building to help us understand how our site performs for real users in all locations, on all browsers. More to come on that! In the interim, we’ve started monitoring more areas of the site with backbone tests so we can give a more complete picture.]]></content:encoded>
  <excerpt:encoded><![CDATA[]]></excerpt:encoded>
  <wp:post_id>30</wp:post_id>
  <wp:post_date>2012-12-09 12:10:20</wp:post_date>
  <wp:post_date_gmt>2012-12-09 12:10:20</wp:post_date_gmt>
  <wp:comment_status>open</wp:comment_status>
  <wp:ping_status>open</wp:ping_status>
  <wp:post_name>lonelyplanet-com-performance-baseline</wp:post_name>
  <wp:status>publish</wp:status>
  <wp:post_parent>0</wp:post_parent>
  <wp:menu_order>0</wp:menu_order>
  <wp:post_type>post</wp:post_type>
  <wp:post_password/>
  <wp:is_sticky>0</wp:is_sticky>
  <category domain="category" nicename="uncategorized"><![CDATA[Uncategorized]]></category>
  <wp:postmeta>
    <wp:meta_key>_publicize_pending</wp:meta_key>
    <wp:meta_value><![CDATA[1]]></wp:meta_value>
  </wp:postmeta>
  <wp:postmeta>
    <wp:meta_key>_elasticsearch_indexed_on</wp:meta_key>
    <wp:meta_value><![CDATA[2012-12-09 12:10:20]]></wp:meta_value>
  </wp:postmeta>
</item>
<item>
  <title>Performance and metrics tools and resources</title>
  <link>http://engineering.lonelyplanet.com/2012/12/09/performance-and-metrics-tools-and-resources/</link>
  <pubDate>Sun, 09 Dec 2012 12:10:55 +0000</pubDate>
  <dc:creator>mjenno</dc:creator>
  <guid isPermaLink="false">http://engineering.lonelyplanet.com/?p=33</guid>
  <description/>
  <content:encoded><![CDATA[As promised, here are all the tools and resources mentioned in our (<a href="https://twitter.com/mjenno">@mjenno</a> and <a href="https://twitter.com/davenolan">@davenolan</a>) <a href="http://velocityconf.com/velocityeu2012/public/schedule/detail/26634">talk at VelocityConf today</a>.

Graphite and friends
<ul>
	<li><a title="graphite, scalable reatime metrics" href="http://graphite.wikidot.com/">graphite</a>: scalable realtime metrics</li>
</ul>
Alternative frontends
<ul>
	<li><a href="https://github.com/paperlesspost/graphiti">graphiti</a></li>
	<li><a href="https://github.com/obfuscurity/tasseo">tasseo</a></li>
	<li><a href="https://github.com/ripienaar/gdash">gdash</a></li>
	<li><a href="https://github.com/obfuscurity/descartes">descartes</a></li>
</ul>
Related tools
<ul>
	<li><a href="https://github.com/etsy/statsd">statsd</a></li>
	<li><a href="https://github.com/lonelyplanet/fozzie">fozzie</a></li>
	<li><a href="https://github.com/lonelyplanet/fozzie">flamsteed</a></li>
	<li><a href="https://github.com/zebrafishlabs/nginx-statsd">statsd plugin for nginx</a></li>
</ul>
Holt-Winters
<ul>
	<li><a href="http://en.wikipedia.org/wiki/Exponential_smoothing">Exponential smoothing</a></li>
	<li><a href="http://forecasters.org/pdfs/foresight/free/Issue19_goodwin.pdf">Introductory article [pdf]</a></li>
	<li><a href="http://www.evanmiller.org/poisson.pdf">Paper evaluating H-W applied to real-time time series [pdf]</a></li>
	<li><a href="http://graphite.readthedocs.org/en/0.9.10/functions.html#graphite.render.functions.holtWintersAberration">It's built into Graphite!</a></li>
</ul>
Also
<ul>
	<li><a href="http://square.github.com/cubism/">cubism</a></li>
	<li><a href="http://d3js.org/">d3 js viz lib</a></li>
	<li><a href="http://jedi.be/blog/2012/01/03/monitoring-wonderland-metrics-api-gateways/">Patrick's excellent 'Monitoring Wonderland' posts</a></li>
</ul>
Continuous experimentation
<ul>
	<li><a href="https://gist.github.com/3833637">Our continuous experimentation chef cookboook</a></li>
	<li><a href="http://openresty.org/">openresty</a> turns Nginx into a Swiss-Army knife</li>
</ul>
And there will be more posts on CE here soon (if there aren't, please harass me on Twitter).]]></content:encoded>
  <excerpt:encoded><![CDATA[]]></excerpt:encoded>
  <wp:post_id>33</wp:post_id>
  <wp:post_date>2012-12-09 12:10:55</wp:post_date>
  <wp:post_date_gmt>2012-12-09 12:10:55</wp:post_date_gmt>
  <wp:comment_status>open</wp:comment_status>
  <wp:ping_status>open</wp:ping_status>
  <wp:post_name>performance-and-metrics-tools-and-resources</wp:post_name>
  <wp:status>publish</wp:status>
  <wp:post_parent>0</wp:post_parent>
  <wp:menu_order>0</wp:menu_order>
  <wp:post_type>post</wp:post_type>
  <wp:post_password/>
  <wp:is_sticky>0</wp:is_sticky>
  <category domain="category" nicename="uncategorized"><![CDATA[Uncategorized]]></category>
  <wp:postmeta>
    <wp:meta_key>_publicize_pending</wp:meta_key>
    <wp:meta_value><![CDATA[1]]></wp:meta_value>
  </wp:postmeta>
  <wp:postmeta>
    <wp:meta_key>_elasticsearch_indexed_on</wp:meta_key>
    <wp:meta_value><![CDATA[2012-12-09 12:10:55]]></wp:meta_value>
  </wp:postmeta>
  <wp:comment>
    <wp:comment_id>26</wp:comment_id>
    <wp:comment_author><![CDATA[Michael Sadler]]></wp:comment_author>
    <wp:comment_author_email>michael@newventurewebsites.com</wp:comment_author_email>
    <wp:comment_author_url>http://www.ses.newventurewebsites.com/</wp:comment_author_url>
    <wp:comment_author_IP>75.159.199.48</wp:comment_author_IP>
    <wp:comment_date>2013-07-05 17:11:41</wp:comment_date>
    <wp:comment_date_gmt>2013-07-05 17:11:41</wp:comment_date_gmt>
    <wp:comment_content><![CDATA[I'm not sure if this fits, but for free web based graphing I like to use Flot by jQuery. Need to use JSON to make it talk to the back-end script.]]></wp:comment_content>
    <wp:comment_approved>1</wp:comment_approved>
    <wp:comment_type/>
    <wp:comment_parent>0</wp:comment_parent>
    <wp:comment_user_id>0</wp:comment_user_id>
    <wp:commentmeta>
      <wp:meta_key>akismet_result</wp:meta_key>
      <wp:meta_value>false</wp:meta_value>
    </wp:commentmeta>
    <wp:commentmeta>
      <wp:meta_key>akismet_history</wp:meta_key>
      <wp:meta_value>a:4:{s:4:"time";d:1373044302.2137699127197265625;s:7:"message";s:28:"Akismet cleared this comment";s:5:"event";s:9:"check-ham";s:4:"user";s:0:"";}</wp:meta_value>
    </wp:commentmeta>
    <wp:commentmeta>
      <wp:meta_key>jabber_published</wp:meta_key>
      <wp:meta_value>1373273010</wp:meta_value>
    </wp:commentmeta>
    <wp:commentmeta>
      <wp:meta_key>akismet_history</wp:meta_key>
      <wp:meta_value>a:4:{s:4:"time";d:1373273010.257814884185791015625;s:7:"message";s:45:"mjenno changed the comment status to approved";s:5:"event";s:15:"status-approved";s:4:"user";s:6:"mjenno";}</wp:meta_value>
    </wp:commentmeta>
  </wp:comment>
</item>
<item>
  <title>Fozzie Updates</title>
  <link>http://engineering.lonelyplanet.com/2012/12/09/fozzie-updates/</link>
  <pubDate>Sun, 09 Dec 2012 12:11:22 +0000</pubDate>
  <dc:creator>mjenno</dc:creator>
  <guid isPermaLink="false">http://engineering.lonelyplanet.com/?p=37</guid>
  <description/>
  <content:encoded><![CDATA[This week we received a pull request to the <a href="https://github.com/lonelyplanet/fozzie">Fozzie</a> gem, which enabled developers to turn off the Fozzie Rails Middleware when used within a Rails application.

After some thinking I felt a better way to handle this was to abstract the Rails specific functionality into a seperate Gem, in the same pattern as the RSpec and RSpec Rails gems.

It also felt like a good time to promote Fozzie to Version 1.0.0, after some positive feedback I received at the<a href="http://www.meetup.com/London-Web-Performance-Group/events/67296732/">WebPerfDay</a> on Friday.

Therefore, <a href="http://rubygems.org/gems/fozzie/versions/1.0.0">Fozzie 1.0.0</a> is now up and requires you to add the following to your Rails application to monitor your Controller methods:

<code>gem 'fozzie_rails'</code>

If you want to use Fozzie in your Rails application, but without the Controller monitoring, use:

<code>gem 'fozzie'</code>

A big thank you to all who have so far contributed code and comments to Fozzie.]]></content:encoded>
  <excerpt:encoded><![CDATA[]]></excerpt:encoded>
  <wp:post_id>37</wp:post_id>
  <wp:post_date>2012-12-09 12:11:22</wp:post_date>
  <wp:post_date_gmt>2012-12-09 12:11:22</wp:post_date_gmt>
  <wp:comment_status>open</wp:comment_status>
  <wp:ping_status>open</wp:ping_status>
  <wp:post_name>fozzie-updates</wp:post_name>
  <wp:status>publish</wp:status>
  <wp:post_parent>0</wp:post_parent>
  <wp:menu_order>0</wp:menu_order>
  <wp:post_type>post</wp:post_type>
  <wp:post_password/>
  <wp:is_sticky>0</wp:is_sticky>
  <category domain="category" nicename="uncategorized"><![CDATA[Uncategorized]]></category>
  <wp:postmeta>
    <wp:meta_key>_publicize_pending</wp:meta_key>
    <wp:meta_value><![CDATA[1]]></wp:meta_value>
  </wp:postmeta>
  <wp:postmeta>
    <wp:meta_key>_elasticsearch_indexed_on</wp:meta_key>
    <wp:meta_value><![CDATA[2012-12-09 12:11:22]]></wp:meta_value>
  </wp:postmeta>
</item>
<item>
  <title>London ElasticSearch user group #1</title>
  <link>http://engineering.lonelyplanet.com/2012/12/09/london-elasticsearch-user-group-1/</link>
  <pubDate>Sun, 09 Dec 2012 12:11:54 +0000</pubDate>
  <dc:creator>mjenno</dc:creator>
  <guid isPermaLink="false">http://engineering.lonelyplanet.com/?p=40</guid>
  <description/>
  <content:encoded><![CDATA[One of the great things about working for Lonely Planet is the opportunity to get out and about at meetups and conferences. Last week we organised and sponsored the first London ElasticSearch user group meetup.

We had two talks. <a href="https://twitter.com/andrew_clegg">Andrew Clegg</a> introduced his <a href="https://github.com/ptdavteam/elasticsearch-approx-plugin">ElasticSearch plugin for fast approximations</a>, which builds on the probabilistic data structures provided by <a href="https://github.com/clearspring/stream-lib">Clearspring's stream-lib</a>. As well as a clever piece of work in its own right, I think it shows one of the strengths of ES, its extensibility. <a href="http://bit.ly/andrew-clegg-cardinality-es">Check out the slides.</a>

Next up was our very own <a href="https://github.com/marckysharky">Marc Watts</a>. Marc introduced some of the tools and techniques we've employed at LP to roll out ElaticSearch as fast as possible. Marc picked up on some of the speed bumps we found with integration testing, Tire, and monitoring. He also showed some live metrics showing a healthy, happy ElasticSearch cluster.

At LP, we use ElasticSearch as our primary document store, and it's the source of truth for our 'view of the world'. By building the whole site on a search engine, we can scale our editorial team and enable them to curate an enormous amount of content. (A different kind of scalability challenge from the ones we normally talk about on this blog.)

Finally, we were lucky enough to have a Q&amp;A with <a href="https://twitter.com/kimchy">Shay Bannon</a> and <a href="https://twitter.com/uboness">Uri Hoeness</a> from ElasticSearch. They were in town to deliver training (highly recommended if you're looking for a deep dive in ES internals and production usage). Their session covered a ton of interesting and useful information, some of which I've tried to précis here (any inaccuracies are down to my note-taking skill, not Shay or Uri):
<ul>
	<li>The team aim for consistency across languages for the client libs, e.g. standard names and data structures for low-level methods. Look out for an overhaul for Tire and others.</li>
	<li>Replacing HTTP with another standard e.g. protobufs or Thrift would not be a huge win: the important thing is realy the quality of the underlying HTTP client libs. For example, not all Ruby HTTP libs support<code>keep-alive</code>, parsing headers in Perl takes sooo long</li>
	<li>For 1.0, some good things to have would be (a) no full restarts for major upgrades (b) better story for loading data into memory (Lucene 4.0 will help) (c) backoffs (d) better story for snapshot/restore</li>
	<li>New in 0.20 are warmers: on refresh, just before results are available, the warmer searches are run so first users won't hit disk</li>
	<li>0.21+ will focus on upgrade to Lucene 4.0</li>
	<li>Field data cache loads all fields even if all queries are restricted to tight filter. This is because other queries might need theproper data</li>
	<li>Nested queries are much faster than parent/child queries (and probably faster than any B-tree-based document store). Parent/child allows for documents with different lifecycles, but the docs have to be joined in memory</li>
	<li>Shay doesn't believe that SSL between nodes is the full story for thorough node security. Right now, you can maybe do something with nginx proxies in front of each node.</li>
	<li>You can use ES as primary doc store. But recommendation is to have the ability to reindex everything. At least one ES user has PBs of data in ES but also flat files on S3</li>
	<li>Will there be a way of splitting shards? Well, just 10 shards will get you way far. Also if you don't identify your partitioning key, you're in trouble anyway e.g. MongoDB clusters die cos folks add nodes when they're at 80% capacity, but splitting is expensive and takes more than the remaining 20%... Shay gave a<a href="http://vimeo.com/album/1968418/video/44716955">talk on this at BerlinBuzzwords</a>.</li>
</ul>
The next #lesug meetup will probably take place end of January 2013. For updates and more information:
<ul>
	<li>follow <a href="https://twitter.com/elastic_london">@elastic_london</a></li>
	<li>check the <a href="https://groups.google.com/forum/#!forum/elasticsearch">ElasticSearch mailing list</a> for announcements</li>
</ul>
At some point soon we'll get set up on MeetUp.com, too.

So thanks very much to our speakers, and Shay and Uri, and everyone who came along for a chat.

Thanks also to Lonely Planet for sponsoring the evening's pizza and drinks. (This was the first meetup I've organised so I was mighty relieved to find I'd ordered enough pizza.)

One last thing. If you're interested in working with ElasticSearch, we're hiring.]]></content:encoded>
  <excerpt:encoded><![CDATA[]]></excerpt:encoded>
  <wp:post_id>40</wp:post_id>
  <wp:post_date>2012-12-09 12:11:54</wp:post_date>
  <wp:post_date_gmt>2012-12-09 12:11:54</wp:post_date_gmt>
  <wp:comment_status>open</wp:comment_status>
  <wp:ping_status>open</wp:ping_status>
  <wp:post_name>london-elasticsearch-user-group-1</wp:post_name>
  <wp:status>publish</wp:status>
  <wp:post_parent>0</wp:post_parent>
  <wp:menu_order>0</wp:menu_order>
  <wp:post_type>post</wp:post_type>
  <wp:post_password/>
  <wp:is_sticky>0</wp:is_sticky>
  <category domain="category" nicename="uncategorized"><![CDATA[Uncategorized]]></category>
  <wp:postmeta>
    <wp:meta_key>_publicize_pending</wp:meta_key>
    <wp:meta_value><![CDATA[1]]></wp:meta_value>
  </wp:postmeta>
  <wp:postmeta>
    <wp:meta_key>_elasticsearch_indexed_on</wp:meta_key>
    <wp:meta_value><![CDATA[2012-12-09 12:11:54]]></wp:meta_value>
  </wp:postmeta>
</item>
<item>
  <title>The Xmas Gift of IAM Self Service</title>
  <link>http://engineering.lonelyplanet.com/2012/12/23/the-xmas-gift-of-iam-self-service/</link>
  <pubDate>Sun, 23 Dec 2012 22:09:24 +0000</pubDate>
  <dc:creator>mjenno</dc:creator>
  <guid isPermaLink="false">http://engineering.lonelyplanet.com/?p=57</guid>
  <description/>
  <content:encoded><![CDATA[<strong>Update: 9 April 2013
AWS has announced an update to IAM which allows the use of variables which makes this process much easier: http://docs.aws.amazon.com/IAM/latest/UserGuide/PolicyVariables.html. This post has been updated to reflect these changes.</strong>

When we created <a href="http://aws.amazon.com/iam/" title="IAM" target="_blank">IAM</a> accounts for our team, we had a desire to as self service as possible. Ideally, we wanted to provide a username and temporary password and then have users be able to set themselves up an access key, security certificate and MFA and be able to manage this themselves ongoing. However, this obviously couldn't be at the expense of security. We needed to ensure that users could only modify their own information and if we remove a user from our account they’re gone.

On the surface, this seemed like a trivial problem, we'd simply generate a policy for full IAM access for each individual user and that would be the end of it:

{
  "Statement": [
    {
      "Sid": "Stmt1356297700489",
      "Action": [
        "iam:*"
      ],
      "Effect": "Allow",
      "Resource": [
        "arn:aws:iam::049718304780:ACCOUNT#:user/${aws:username}"
      ]
    }
  ]
}

Unfortunately, the major challenge we faced was that IAM permissions through the console appears to be an all or nothing system. Even if you have full IAM access for your own user, you can’t do anything as you don’t have any permissions to list other users:

<a href="http://engineering.lonelyplanet.com/2012/12/23/the-xmas-gift-of-iam-self-service/screen-shot-2012-12-24-at-08-24-39/" rel="attachment wp-att-59"><img class="alignnone size-medium wp-image-59" alt="IAM fail" src="http://lpengineering.files.wordpress.com/2012/12/screen-shot-2012-12-24-at-08-24-39.png?w=300" width="300" height="114" /></a>

After much investigation (trial &amp; error), we found the only way to achieve what we wanted was giving groups full IAM read only access and controlling write access with individual policies. While this may seem like a security vulnerability, the IAM console is cleverly designed to not provide any secret information. It may not be ideal that all users can see the groups that are setup, who has access keys etc., but none of this information is particularly useful.

This is the policy we’re using at the moment:

{
  "Statement": [
    {
      "Action": [
        "iam:*Password*",
        "iam:*AccessKey*",
        "iam:*SigningCertificate*",
        "iam:*MFADevice*",
        "iam:UpdateLoginProfile"
      ],
      "Effect": "Allow",
      "Resource": [
        "arn:aws:iam::ACCOUNT#:user/${aws:username}"
      ]
    },
      "Action": [
        "iam:*MFADevice*"
      ],
      "Effect": "Allow",
      "Resource": [
        "arn:aws:iam::ACCOUNT#:mfa/${aws:username}"
      ]
    }
  ]
}

Properly formatted code is available in this <a href="https://gist.github.com/4366364" title="IAM policy for self service" target="_blank">gist</a>. We have had to change this a couple of time as AWS has made modifications to the names of IAM permissions. Unfortunately, we haven't found this out until someone has told us they can't do something.

<del datetime="2013-04-09T15:49:18+00:00">With our relatively small number of users, setting this up manually wasn’t too onerous but it also should be fairly straightforward to script. If anyone does get around to scripting it, please share! We'll probably end up doing it soon anyway.</del>

Hopefully this post will become redundant soon if AWS improves how it handles these permissions.]]></content:encoded>
  <excerpt:encoded><![CDATA[]]></excerpt:encoded>
  <wp:post_id>57</wp:post_id>
  <wp:post_date>2012-12-23 22:09:24</wp:post_date>
  <wp:post_date_gmt>2012-12-23 22:09:24</wp:post_date_gmt>
  <wp:comment_status>open</wp:comment_status>
  <wp:ping_status>open</wp:ping_status>
  <wp:post_name>the-xmas-gift-of-iam-self-service</wp:post_name>
  <wp:status>publish</wp:status>
  <wp:post_parent>0</wp:post_parent>
  <wp:menu_order>0</wp:menu_order>
  <wp:post_type>post</wp:post_type>
  <wp:post_password/>
  <wp:is_sticky>0</wp:is_sticky>
  <category domain="category" nicename="uncategorized"><![CDATA[Uncategorized]]></category>
  <wp:postmeta>
    <wp:meta_key>_publicize_pending</wp:meta_key>
    <wp:meta_value><![CDATA[1]]></wp:meta_value>
  </wp:postmeta>
  <wp:postmeta>
    <wp:meta_key>_elasticsearch_indexed_on</wp:meta_key>
    <wp:meta_value><![CDATA[2012-12-23 22:09:24]]></wp:meta_value>
  </wp:postmeta>
</item>
<item>
  <title>IAM fail</title>
  <link>http://engineering.lonelyplanet.com/2012/12/23/the-xmas-gift-of-iam-self-service/screen-shot-2012-12-24-at-08-24-39/</link>
  <pubDate>Sun, 23 Dec 2012 21:25:36 +0000</pubDate>
  <dc:creator>mjenno</dc:creator>
  <guid isPermaLink="false">http://lpengineering.files.wordpress.com/2012/12/screen-shot-2012-12-24-at-08-24-39.png</guid>
  <description/>
  <content:encoded><![CDATA[]]></content:encoded>
  <excerpt:encoded><![CDATA[]]></excerpt:encoded>
  <wp:post_id>59</wp:post_id>
  <wp:post_date>2012-12-23 21:25:36</wp:post_date>
  <wp:post_date_gmt>2012-12-23 21:25:36</wp:post_date_gmt>
  <wp:comment_status>open</wp:comment_status>
  <wp:ping_status>open</wp:ping_status>
  <wp:post_name>screen-shot-2012-12-24-at-08-24-39</wp:post_name>
  <wp:status>inherit</wp:status>
  <wp:post_parent>57</wp:post_parent>
  <wp:menu_order>0</wp:menu_order>
  <wp:post_type>attachment</wp:post_type>
  <wp:post_password/>
  <wp:is_sticky>0</wp:is_sticky>
  <wp:attachment_url>http://lpengineering.files.wordpress.com/2012/12/screen-shot-2012-12-24-at-08-24-39.png</wp:attachment_url>
</item>
<item>
  <title>Chef staging environment</title>
  <link>http://engineering.lonelyplanet.com/2013/03/08/chef-staging-environment-2/</link>
  <pubDate>Fri, 08 Mar 2013 11:07:23 +0000</pubDate>
  <dc:creator>julienberard</dc:creator>
  <guid isPermaLink="false">http://engineering.lonelyplanet.com/?p=81</guid>
  <description/>
  <content:encoded><![CDATA[<strong><span style="line-height:16px;">Current situation</span></strong>

We are using <a title="Chef" href="http://www.opscode.com/chef/" target="_blank">Chef</a> in order to deploy our apps. It is a really great tool, associated with Git it allow us to work all together an change the configuration to our live environment by a simple push.

In order to achieve that we have the following process :

Git commit --&gt; Jenkins --&gt; Build agent --&gt; Chef Server
<ol>
	<li><span style="line-height:1.5;">Someone does a commit on GIT</span></li>
	<li><span style="line-height:1.5;">Jenkins monitor the repo, if a commit has been done it will pull the commit on a build-agent which will test the commit (<a href="http://acrmp.github.com/foodcritic/" target="_blank">Foodcritic</a>) </span></li>
	<li><span style="line-height:1.5;">If the test succeed the build-agent runs a script on the Chef Server which pull the change then load it into Chef</span></li>
</ol>
It worked pretty well, the problem was that usually you will pass the Footcritic test but something else will failed during deployment, something you cannot detect without running chef-client on a server. Because we only had a production environment, every time someone broke chef, it impacted all our server. It was not a major problem as we don't run chef-client as a daemon  so until someone manually ran chef-client on a server nothing was impacted. It was almost true, because we are using AWS autoscaling which can trigger the build of a new server using chef.

As you can imagine it started to be a big issue when we were working on chef while some new code was pushed to our server (we are using continuous integration).

<strong><span style="font-size:medium;line-height:16px;">What do we want to fix ?</span></strong>
<ul>
	<li><span style="line-height:16px;">Detect all possible issues before to deploy our chef changes</span></li>
</ul>
The only way we have to test Chef in a real environment is run it on a server, you cannot really use the same server each time because some chef role could conflict with each other, and you would have to uninstall everything before each new test run. Therefore we need to boot a brand new server. Possible solutions to automatically boot a new server ?
<ol>
	<li><span style="line-height:16px;">AWS EC2 : That's what we use for production, the only issue is that you have to pay 1 hour every time you boot an instance.</span></li>
	<li>Another cloud service : AWS works very well for us, we don;t want to bother with another one</li>
	<li>Our own virtualisation product : It has to be easy to manipulate from our current infrastructure and it's better if it is opensource</li>
</ol>
We chose to use <a href="http://lxc.sourceforge.net/">LXC</a> , it is built in the Linux kernel, the overhead is minimal, and it is really easy to script as a VM is as simple as a folder
<ul>
	<li><span style="line-height:1.5;">Do not impact production when we work on chef changes</span></li>
</ul>
Possible options?
<ol>
	<li><span style="line-height:16px;">Use the chef ENVIRONMENT feature : chef has a build in environment feature, it allow us to use a specific environment, so we can choose on our server if we want to use production or staging, for example. The problem is that it is not as isolated as we would like. First of all when you deploy a cookbook in the staging environment it will simply fix the cookbook version in the environment. So you have to bump cookbook version and be sure you don't update the production cookbook version. Second issue, you don't have version on the Roles or Databags, even if you can define attributes per environment (which is really nice) you cannot change it without impacting the production role. It was the first solution we chose, however its implementation was quite complex, and it was really easy to break production by playing with staging.</span></li>
	<li>Use a second chef server : It is perfect, it is completely isolated from production, and we can change the server we want to use on a client by editing /etc/chef/client.rb. The only problem is that we need to pay for a new server, server which will require monitoring and maintenance</li>
</ol>
We chose the second solution, to be sure at 100% that we will not break production.
<ul>
	<li><span style="line-height:16px;">Automatically boot a LXC server using our staging chef server, and be sure the change succeed before to push it to production</span></li>
</ul>
There are not a lot of ways to test chef, we could have developed our own tools to run a LXC environment running chef-client then a series of test on this LXC server, however we preferred to use <a href="https://github.com/exceedhl/toft">Toft</a> which is a Ruby library based on Cucumber, Rspec and LXC. Toft handles the launch of the LXC container and the Cucumber test against this containers.

<strong>The solution</strong>

We knew our tools, <strong>Chef, Jenkins, LXC, Toft</strong>.

We then had to chose a process that was as simple as possible, as transparent as possible for the users (us) and as automated as possible. After different test we chose the following process =&gt;

Git commit --&gt; Jenkins --&gt; Build agent --&gt; Chef Staging Server --&gt; Toft --&gt; LXC container --&gt; Jenkins -- Build agent --&gt; Chef Production Server
<ol>
	<li>Someone does a commit on GIT</li>
	<li>A first Jenkins job monitors the repo, if a commit has been done it will pull the commit on a build-agent which will test the commit (<a href="http://acrmp.github.com/foodcritic/" target="_blank">Foodcritic</a>)</li>
	<li>If the test succeeds the build-agent runs a script on the Chef <strong>STAGING</strong> Server</li>
	<li>Toft will be run on our LXC server, it will boot a LXC container with the roles we want, then it will test the results (files expected, process running etc...)</li>
	<li>If the Toft run and test succeeds, run a second Jenkins job</li>
	<li>A second Jenkins job will retrieve the last successful build (validated by toft), then it will tell to a build-agent to pull this specific successful build on the chef <strong>PRODUCTION</strong> server and to load it into Chef</li>
</ol>
That's it, a fully automated test solution for Chef.]]></content:encoded>
  <excerpt:encoded><![CDATA[]]></excerpt:encoded>
  <wp:post_id>81</wp:post_id>
  <wp:post_date>2013-03-08 11:07:23</wp:post_date>
  <wp:post_date_gmt>2013-03-08 11:07:23</wp:post_date_gmt>
  <wp:comment_status>open</wp:comment_status>
  <wp:ping_status>open</wp:ping_status>
  <wp:post_name>chef-staging-environment-2</wp:post_name>
  <wp:status>publish</wp:status>
  <wp:post_parent>0</wp:post_parent>
  <wp:menu_order>0</wp:menu_order>
  <wp:post_type>post</wp:post_type>
  <wp:post_password/>
  <wp:is_sticky>0</wp:is_sticky>
  <category domain="post_tag" nicename="chef"><![CDATA[chef]]></category>
  <category domain="post_tag" nicename="ci"><![CDATA[ci]]></category>
  <category domain="post_tag" nicename="lxc"><![CDATA[lxc]]></category>
  <category domain="post_tag" nicename="staging"><![CDATA[staging]]></category>
  <category domain="post_tag" nicename="test"><![CDATA[test]]></category>
  <category domain="post_tag" nicename="toft"><![CDATA[toft]]></category>
  <category domain="category" nicename="uncategorized"><![CDATA[Uncategorized]]></category>
  <wp:postmeta>
    <wp:meta_key>draftfeedback_requests</wp:meta_key>
    <wp:meta_value><![CDATA[a:1:{s:30:"mark.jennings@lonelyplanet.com";a:3:{s:3:"key";s:13:"5130c95a8c0c5";s:4:"time";s:10:"1362151770";s:7:"user_id";s:8:"43262790";}}]]></wp:meta_value>
  </wp:postmeta>
  <wp:postmeta>
    <wp:meta_key>_publicize_pending</wp:meta_key>
    <wp:meta_value><![CDATA[1]]></wp:meta_value>
  </wp:postmeta>
  <wp:postmeta>
    <wp:meta_key>_elasticsearch_indexed_on</wp:meta_key>
    <wp:meta_value><![CDATA[2013-03-08 11:07:23]]></wp:meta_value>
  </wp:postmeta>
  <wp:comment>
    <wp:comment_id>24</wp:comment_id>
    <wp:comment_author><![CDATA[Mark Bate]]></wp:comment_author>
    <wp:comment_author_email>mark.bate@mac.com</wp:comment_author_email>
    <wp:comment_author_url/>
    <wp:comment_author_IP>93.220.97.218</wp:comment_author_IP>
    <wp:comment_date>2013-06-04 10:13:34</wp:comment_date>
    <wp:comment_date_gmt>2013-06-04 10:13:34</wp:comment_date_gmt>
    <wp:comment_content><![CDATA[I like the use of LXC for the testing. I believe Chef-Cucumber (one of the early test frameworks) did a similar thing, but it sounds like Toft might be a bit nicer if you plan on using Rspec.

Another way is rather than treating the Chef Repo as a project, treat each cookbook as it's own project &amp; test it with something like Test-Kitchen (basically Vagrant + tests) before uploading to the Chef Server.
I highly recommend watching Jamie Winsor's recent Chef Conf talk on "The Berkshelf Way": http://www.youtube.com/watch?v=hYt0E84kYUI
And then reading Joshua Timberman's blog (http://jtimberman.housepub.org), there's a lot of recent articles about getting up &amp; running with Test-Kitchen.

Also, something else we recently tried at 6Wunderkinder was to think of all application servers as being disposable. Rather than deploy new code over the top of the old servers, we use Chef-Solo to build a new AMI with the latest code. We then boot instances of that new AMI &amp; pull the old servers out of the load balancer. You need to be a bit careful with your sessions, but it's a nice way to canary test a release - if something goes wrong, you just switch the new nodes out &amp; the old ones back in.
It also makes it nice &amp; quick to auto-scale, as everything is baked into the AMI, the only Chef stuff you may need to do is last minute configuration.]]></wp:comment_content>
    <wp:comment_approved>1</wp:comment_approved>
    <wp:comment_type/>
    <wp:comment_parent>0</wp:comment_parent>
    <wp:comment_user_id>0</wp:comment_user_id>
    <wp:commentmeta>
      <wp:meta_key>akismet_result</wp:meta_key>
      <wp:meta_value>false</wp:meta_value>
    </wp:commentmeta>
    <wp:commentmeta>
      <wp:meta_key>akismet_history</wp:meta_key>
      <wp:meta_value>a:4:{s:4:"time";d:1370340815.6985399723052978515625;s:7:"message";s:28:"Akismet cleared this comment";s:5:"event";s:9:"check-ham";s:4:"user";s:8:"markbate";}</wp:meta_value>
    </wp:commentmeta>
    <wp:commentmeta>
      <wp:meta_key>jabber_published</wp:meta_key>
      <wp:meta_value>1370340891</wp:meta_value>
    </wp:commentmeta>
    <wp:commentmeta>
      <wp:meta_key>akismet_history</wp:meta_key>
      <wp:meta_value>a:4:{s:4:"time";d:1370340891.376801013946533203125;s:7:"message";s:45:"mjenno changed the comment status to approved";s:5:"event";s:15:"status-approved";s:4:"user";s:6:"mjenno";}</wp:meta_value>
    </wp:commentmeta>
  </wp:comment>
  <wp:comment>
    <wp:comment_id>22</wp:comment_id>
    <wp:comment_author><![CDATA[Tom]]></wp:comment_author>
    <wp:comment_author_email>lonelyplanet@tomvn.com</wp:comment_author_email>
    <wp:comment_author_url>http://tomvn.com/</wp:comment_author_url>
    <wp:comment_author_IP>37.157.32.210</wp:comment_author_IP>
    <wp:comment_date>2013-04-29 10:14:45</wp:comment_date>
    <wp:comment_date_gmt>2013-04-29 10:14:45</wp:comment_date_gmt>
    <wp:comment_content><![CDATA[I like your novel use of LXC. It's a very interesting tech, the only thing that annoys me is that the cgroups don't map to the containerised memory and CPU, which messes with any app that uses free to set up initial memory use (eg: Cassandra) or looks at cores to set up multiple processes.
For my config management testing, I'm looking into a combination of spot instances (they can be almost 10x cheaper), overlayfs on top of / (so that a reboot wipes the machine without billing another hour) and only terminating the test machine an hour after startup to allow multiple config management tests to run in only one billing hour. Testing this way on a small instance can cost under $10 a month.]]></wp:comment_content>
    <wp:comment_approved>1</wp:comment_approved>
    <wp:comment_type/>
    <wp:comment_parent>0</wp:comment_parent>
    <wp:comment_user_id>0</wp:comment_user_id>
    <wp:commentmeta>
      <wp:meta_key>akismet_history</wp:meta_key>
      <wp:meta_value>a:4:{s:4:"time";d:1367230650.406466007232666015625;s:7:"message";s:45:"mjenno changed the comment status to approved";s:5:"event";s:15:"status-approved";s:4:"user";s:6:"mjenno";}</wp:meta_value>
    </wp:commentmeta>
    <wp:commentmeta>
      <wp:meta_key>jabber_published</wp:meta_key>
      <wp:meta_value>1367230650</wp:meta_value>
    </wp:commentmeta>
    <wp:commentmeta>
      <wp:meta_key>akismet_result</wp:meta_key>
      <wp:meta_value>false</wp:meta_value>
    </wp:commentmeta>
    <wp:commentmeta>
      <wp:meta_key>akismet_history</wp:meta_key>
      <wp:meta_value>a:4:{s:4:"time";d:1367230485.2761700153350830078125;s:7:"message";s:28:"Akismet cleared this comment";s:5:"event";s:9:"check-ham";s:4:"user";s:0:"";}</wp:meta_value>
    </wp:commentmeta>
  </wp:comment>
</item>
<item>
  <title>Why we're excited about AWS OpsWorks but won't be using it</title>
  <link>http://engineering.lonelyplanet.com/?p=92</link>
  <pubDate>Wed, 30 Nov -0001 00:00:00 +0000</pubDate>
  <dc:creator>mbarger00</dc:creator>
  <guid isPermaLink="false">http://engineering.lonelyplanet.com/?p=92</guid>
  <description/>
  <content:encoded><![CDATA[]]></content:encoded>
  <excerpt:encoded><![CDATA[]]></excerpt:encoded>
  <wp:post_id>92</wp:post_id>
  <wp:post_date>2013-03-06 15:32:31</wp:post_date>
  <wp:post_date_gmt>0000-00-00 00:00:00</wp:post_date_gmt>
  <wp:comment_status>open</wp:comment_status>
  <wp:ping_status>open</wp:ping_status>
  <wp:post_name>why-were-excited-aws-opsworks</wp:post_name>
  <wp:status>draft</wp:status>
  <wp:post_parent>0</wp:post_parent>
  <wp:menu_order>0</wp:menu_order>
  <wp:post_type>post</wp:post_type>
  <wp:post_password/>
  <wp:is_sticky>0</wp:is_sticky>
  <category domain="category" nicename="uncategorized"><![CDATA[Uncategorized]]></category>
</item>
<item>
  <title>Continuous delivery and ETL: experience report</title>
  <link>http://engineering.lonelyplanet.com/?p=96</link>
  <pubDate>Wed, 30 Nov -0001 00:00:00 +0000</pubDate>
  <dc:creator>dpdnolan</dc:creator>
  <guid isPermaLink="false">http://engineering.lonelyplanet.com/?p=96</guid>
  <description/>
  <content:encoded><![CDATA[]]></content:encoded>
  <excerpt:encoded><![CDATA[]]></excerpt:encoded>
  <wp:post_id>96</wp:post_id>
  <wp:post_date>2013-04-17 13:33:33</wp:post_date>
  <wp:post_date_gmt>0000-00-00 00:00:00</wp:post_date_gmt>
  <wp:comment_status>open</wp:comment_status>
  <wp:ping_status>open</wp:ping_status>
  <wp:post_name/>
  <wp:status>draft</wp:status>
  <wp:post_parent>0</wp:post_parent>
  <wp:menu_order>0</wp:menu_order>
  <wp:post_type>post</wp:post_type>
  <wp:post_password/>
  <wp:is_sticky>0</wp:is_sticky>
  <category domain="category" nicename="uncategorized"><![CDATA[Uncategorized]]></category>
</item>
<item>
  <title>Updating Fozzie</title>
  <link>http://engineering.lonelyplanet.com/?p=98</link>
  <pubDate>Wed, 30 Nov -0001 00:00:00 +0000</pubDate>
  <dc:creator>marckysharky</dc:creator>
  <guid isPermaLink="false">http://engineering.lonelyplanet.com/?p=98</guid>
  <description/>
  <content:encoded><![CDATA[]]></content:encoded>
  <excerpt:encoded><![CDATA[]]></excerpt:encoded>
  <wp:post_id>98</wp:post_id>
  <wp:post_date>2013-07-14 18:46:46</wp:post_date>
  <wp:post_date_gmt>0000-00-00 00:00:00</wp:post_date_gmt>
  <wp:comment_status>open</wp:comment_status>
  <wp:ping_status>open</wp:ping_status>
  <wp:post_name/>
  <wp:status>draft</wp:status>
  <wp:post_parent>0</wp:post_parent>
  <wp:menu_order>0</wp:menu_order>
  <wp:post_type>post</wp:post_type>
  <wp:post_password/>
  <wp:is_sticky>0</wp:is_sticky>
  <category domain="category" nicename="uncategorized"><![CDATA[Uncategorized]]></category>
</item>
<item>
  <title>Reviewing our Metrics and Logging Infrastructure</title>
  <link>http://engineering.lonelyplanet.com/?p=99</link>
  <pubDate>Wed, 30 Nov -0001 00:00:00 +0000</pubDate>
  <dc:creator>marckysharky</dc:creator>
  <guid isPermaLink="false">http://engineering.lonelyplanet.com/?p=99</guid>
  <description/>
  <content:encoded><![CDATA[Since moving lonelyplanet.com to our new cloudy home we've forced ourselves to take a look at the infrastructure we've been running, and re-evaluate where we want to spend our efforts.

What seemed like a simple agenda turned out to be incredibly difficult to process, and even harder to prioritise. The summarised outcome was:
<ul>
	<li>Improve our deployment process</li>
	<li>Spend less time maintaining our Metrics service</li>
	<li>Spend less time maintaining our Logging service</li>
</ul>]]></content:encoded>
  <excerpt:encoded><![CDATA[]]></excerpt:encoded>
  <wp:post_id>99</wp:post_id>
  <wp:post_date>2013-07-16 10:39:38</wp:post_date>
  <wp:post_date_gmt>0000-00-00 00:00:00</wp:post_date_gmt>
  <wp:comment_status>open</wp:comment_status>
  <wp:ping_status>open</wp:ping_status>
  <wp:post_name>reviewing-our-metrics-and-logging-infrastructure</wp:post_name>
  <wp:status>draft</wp:status>
  <wp:post_parent>0</wp:post_parent>
  <wp:menu_order>0</wp:menu_order>
  <wp:post_type>post</wp:post_type>
  <wp:post_password/>
  <wp:is_sticky>0</wp:is_sticky>
  <category domain="category" nicename="uncategorized"><![CDATA[Uncategorized]]></category>
  <wp:postmeta>
    <wp:meta_key>geo_public</wp:meta_key>
    <wp:meta_value><![CDATA[0]]></wp:meta_value>
  </wp:postmeta>
</item>
<item>
  <title>Fast, dependable, atomic Rails deploys with packages [part 1]</title>
  <link>http://engineering.lonelyplanet.com/?p=103</link>
  <pubDate>Wed, 30 Nov -0001 00:00:00 +0000</pubDate>
  <dc:creator>julienberard</dc:creator>
  <guid isPermaLink="false">http://engineering.lonelyplanet.com/?p=103</guid>
  <description/>
  <content:encoded><![CDATA[Lonely Planet celebrates its 40 years,  the website itself was launched around 14 years ago. We continuously refactor the website and this year has been a big step on the release of our new code based on Ruby rather than Java. After several months, we learnt about our new stack and how to make the best of it.

One of our issue was to make our deployment process fast, dependable and atomic, indeed what was working like a charm during our testing phase was a bit different in production under load.

Let's see how we made reliable deployment and reduce their time by <span style="color:#ff0000;">96 %</span><strong></strong>

<span style="font-size:2.4em;line-height:1.5em;">Context</span>

Here at Lonely Planet, most of our apps are using a standard rails stack based on nginx and unicorn. When we released our first application based on this stack in production we were using our configuration management tool (Chef) in order to deploy our code changes, the process roughly looked like that :

<a href="http://lpengineering.files.wordpress.com/2013/10/flowchart-with-chef1.png"><img class="aligncenter size-large wp-image-114" alt="flowchart-with-chef" src="http://lpengineering.files.wordpress.com/2013/10/flowchart-with-chef1.png?w=640" width="640" height="458" /></a>
<ol>
	<li>Push you code to the SCM (git on github)</li>
	<li>Trigger the first job to test the app (Jenkins)</li>
	<li>Trigger the second job to deploy the app (Jenkins) which was a Chef run =&gt; <a href="http://docs.opscode.com/resource_deploy.html">chef deploy resource </a></li>
</ol>
<h1>Challenges</h1>
This approach worked well for a while, especially when we didn't have a lot of deployments and projects following this process. Indeed as soon as we started to continuously deploy more and more in production we faced the following issues.
<h2>Dependencies</h2>
<h3>Github</h3>
Each deploy was pulling the code from github (so were some Gems). Which means it was quite slow, and each time Github encountered issue (Ddos attack or so) it was impacting our deploy process.
<h3>Rubygems.org</h3>
Each deploy was bundling the app, so if rubygems was not operational we were not able to get our app working.
<h2>Time / Resources</h2>
Between 8 and 10 minutes, CPU usage maxed out for 5 minutes, latency increase.

Because we were using Chef, we were wasting time on checking the state of the whole server where the only thing mattering was the code release.

<span style="line-height:1.5;">We were consuming a lot of CPU resources during the bundle of the app on all servers, making the live app slower (gems download/install/compilation).</span>

<span style="line-height:1.5;">We were using a lot of CPU resources during the assets precompile phase.</span>
<h2>Rollback</h2>
The rollback process was a bit messy and slow : we had to do some changes to chef, which was then tested and deployed.
<h2>Inconsistent</h2>
<span style="line-height:1.5;">The chef deploy resource is not ideal. If your deployment failed in the middle of callback (before_restart) by example, you can end up with an inconsistent state (which doesn't help when you want to rollback).  Some behavior are annoying (the deploy resource trying to chown every file in your app folder (even symlink point to shares) by example.</span>

We had to force a deploy when we wanted to change a the application's configuration.

We needed a solution to fix all this breaking point.
<h1>Goals</h1>
As mentioned before we wanted a process fast and dependable, solving all the above issues. That's why we decided to move to a packaged process. It should fix the dependencies, the CPU issues (no more bundle on the servers), ease the rollback process, make the deploy as idempotent as possible, reduce the deploy time due to a focused package deploy rather than "a chef server" deploy.
<h1>But first</h1>
<h2>Split code from environment configuration</h2>
It was the first step in our new process. To achieve a clean package with code only we had to be sure the configuration was out of the app. In the meantime it has to be simple to deploy in production and easy to adapt to the developer's local environment. We decided to use <a href="https://github.com/bkeepers/dotenv">https://github.com/bkeepers/dotenv</a>. It allow us to load ENV variables from an ENV file, we told dotenv the fiel location is stored is an ENV variable. Which means you have something like, CONF_MYAPP=/etc/MYAPP/env Then in your app's config
<pre class="prettyprint"><code class="language-ruby">require 'dotenv'
Dotenv.tap do |de|
  de.load
  de.load(ENV['CONF_MYAPP']) if ENV['CONF_MYAPP']
end
</code></pre>
It was a simple step, but crucial if we wanted to implement packaging.
<h1>Then</h1>
<h2>Package the APP</h2>
<h3>Inside</h3>
We knew what we wanted to put in our package.
<ul>
	<li>The code</li>
	<li>The gems (bundled in the package itself)</li>
	<li>Needed files only, so we have to remove useless folders (spec/git/doc etc...).</li>
</ul>
We didn't add the assets to the package because we chose to ship them to an S3 bucket : <span style="color:#99ccff;">Assets pipeline</span>

We didn't want to add more, because we focused on having a package having the strict minimum to release a unicorn app with the desired code version.
<h3>Container</h3>
All our systems are based on Ubuntu, therefore at least 2 solutions were possible concerning the package format :
<ul>
	<li>tarball</li>
	<li>debian package</li>
</ul>
Even if the tarball was the easiest solution we didn't want to have tarball + deploy script. It didn't look good enough for a long term solution, due to the lack of version management and metadata. We wanted to be sure to have a consistent state on a server, with some easy step deploy, rollback, or deploy the code at a well known state. The deb package looked like the best solution, we would be able to :
<ul>
	<li>Version our releases (not only the filename) : so our system will be aware of the code version we use. It will be pretty simple to integrate to our bootstrap process as chef is really good at managing apt packages</li>
	<li>Add metadata : release commit, code variant, so it is easy to know which version is live</li>
	<li>apt/aptitude would manage the deploy phase : we don't have to worry when we upgrade from when version to another, when we downgrade either.  A lot of work have already be done to manage software installation on Debian/Ubuntu, so why reinvent the wheel?</li>
	<li>Add dependencies : we can include dependencies on system libraries, by example libxml2-dev/libsqlite straight away on our code package. So a package is able to start a full working app.</li>
</ul>
So now we have our code ready to use external configuration, a package to deploy the code, how will we use it?
<h1>Final process</h1>
There are few more logical steps in the process than with the Chef integration.

<a href="http://lpengineering.files.wordpress.com/2013/10/flowchart-with-package.png"><img class="aligncenter size-large wp-image-117" alt="flowchart-with-package" src="http://lpengineering.files.wordpress.com/2013/10/flowchart-with-package.png?w=640" width="640" height="610" /></a>
<ol>
	<li>Push the code</li>
	<li>CI test the code</li>
	<li>CI build the package</li>
	<li>CI deploy the package</li>
</ol>
It will be different if you boot a server from scratch, because it is not triggered by a code push
<ol>
	<li>Chef deploy the server AND the app configuration</li>
	<li>Chef deploy the last package</li>
</ol>
<h1>Outcome</h1>
<ul>
	<li>Reduction of our deployment time from an average of 10 minutes per server to 25 seconds.</li>
	<li>No impact anymore from the different Github and Rubygems.org outage.</li>
	<li>Rollback step is easy and fast</li>
	<li>Latency is constant even while deploying</li>
</ul>
<span style="line-height:1.5;">In the next article we will see in details which tools have been used, and the detailed steps. We needed to be able to build the packages, host our deb repository, remotely trigger the package install and configure the environment.</span>]]></content:encoded>
  <excerpt:encoded><![CDATA[]]></excerpt:encoded>
  <wp:post_id>103</wp:post_id>
  <wp:post_date>2013-10-11 12:14:58</wp:post_date>
  <wp:post_date_gmt>0000-00-00 00:00:00</wp:post_date_gmt>
  <wp:comment_status>open</wp:comment_status>
  <wp:ping_status>open</wp:ping_status>
  <wp:post_name/>
  <wp:status>draft</wp:status>
  <wp:post_parent>0</wp:post_parent>
  <wp:menu_order>0</wp:menu_order>
  <wp:post_type>post</wp:post_type>
  <wp:post_password/>
  <wp:is_sticky>0</wp:is_sticky>
  <category domain="post_tag" nicename="continuous"><![CDATA[continuous]]></category>
  <category domain="post_tag" nicename="deploy"><![CDATA[deploy]]></category>
  <category domain="post_tag" nicename="package"><![CDATA[package]]></category>
  <category domain="post_tag" nicename="rails"><![CDATA[rails]]></category>
  <category domain="category" nicename="uncategorized"><![CDATA[Uncategorized]]></category>
  <wp:postmeta>
    <wp:meta_key>draftfeedback_requests</wp:meta_key>
    <wp:meta_value><![CDATA[a:1:{s:27:"dave.nolan@lonelyplanet.com";a:3:{s:3:"key";s:13:"5252a4ad97f83";s:4:"time";s:10:"1381147821";s:7:"user_id";s:8:"43262790";}}]]></wp:meta_value>
  </wp:postmeta>
  <wp:postmeta>
    <wp:meta_key>draft_feedback</wp:meta_key>
    <wp:meta_value><![CDATA[a:1:{s:27:"dave.nolan@lonelyplanet.com";a:1:{i:0;a:2:{s:4:"time";s:10:"1381415355";s:7:"content";s:262:"Title => 'Fast, dependable, atomic Rails deploys with packages [part 1]'

Some typos etc.:
- Lonelyplanet =>  Lonely Planet
- app => apps
- link to dotenv

Subheaders

- assets?
- extra challenge: high CPU during bundle/asset compilation
- graphics
- outcome?


";}}}]]></wp:meta_value>
  </wp:postmeta>
</item>
<item>
  <title>flowchart-with-chef</title>
  <link>http://engineering.lonelyplanet.com/?attachment_id=113</link>
  <pubDate>Fri, 11 Oct 2013 11:16:42 +0000</pubDate>
  <dc:creator>julienberard</dc:creator>
  <guid isPermaLink="false">http://lpengineering.files.wordpress.com/2013/10/flowchart-with-chef.png</guid>
  <description/>
  <content:encoded><![CDATA[]]></content:encoded>
  <excerpt:encoded><![CDATA[]]></excerpt:encoded>
  <wp:post_id>113</wp:post_id>
  <wp:post_date>2013-10-11 11:16:42</wp:post_date>
  <wp:post_date_gmt>2013-10-11 11:16:42</wp:post_date_gmt>
  <wp:comment_status>open</wp:comment_status>
  <wp:ping_status>open</wp:ping_status>
  <wp:post_name>flowchart-with-chef</wp:post_name>
  <wp:status>inherit</wp:status>
  <wp:post_parent>103</wp:post_parent>
  <wp:menu_order>0</wp:menu_order>
  <wp:post_type>attachment</wp:post_type>
  <wp:post_password/>
  <wp:is_sticky>0</wp:is_sticky>
  <wp:attachment_url>http://lpengineering.files.wordpress.com/2013/10/flowchart-with-chef.png</wp:attachment_url>
</item>
<item>
  <title>flowchart-with-chef</title>
  <link>http://engineering.lonelyplanet.com/?attachment_id=114</link>
  <pubDate>Fri, 11 Oct 2013 11:17:32 +0000</pubDate>
  <dc:creator>julienberard</dc:creator>
  <guid isPermaLink="false">http://lpengineering.files.wordpress.com/2013/10/flowchart-with-chef1.png</guid>
  <description/>
  <content:encoded><![CDATA[]]></content:encoded>
  <excerpt:encoded><![CDATA[]]></excerpt:encoded>
  <wp:post_id>114</wp:post_id>
  <wp:post_date>2013-10-11 11:17:32</wp:post_date>
  <wp:post_date_gmt>2013-10-11 11:17:32</wp:post_date_gmt>
  <wp:comment_status>open</wp:comment_status>
  <wp:ping_status>open</wp:ping_status>
  <wp:post_name>flowchart-with-chef-2</wp:post_name>
  <wp:status>inherit</wp:status>
  <wp:post_parent>103</wp:post_parent>
  <wp:menu_order>0</wp:menu_order>
  <wp:post_type>attachment</wp:post_type>
  <wp:post_password/>
  <wp:is_sticky>0</wp:is_sticky>
  <wp:attachment_url>http://lpengineering.files.wordpress.com/2013/10/flowchart-with-chef1.png</wp:attachment_url>
</item>
<item>
  <title>flowchart-with-package</title>
  <link>http://engineering.lonelyplanet.com/?attachment_id=117</link>
  <pubDate>Fri, 11 Oct 2013 11:46:28 +0000</pubDate>
  <dc:creator>julienberard</dc:creator>
  <guid isPermaLink="false">http://lpengineering.files.wordpress.com/2013/10/flowchart-with-package.png</guid>
  <description/>
  <content:encoded><![CDATA[]]></content:encoded>
  <excerpt:encoded><![CDATA[]]></excerpt:encoded>
  <wp:post_id>117</wp:post_id>
  <wp:post_date>2013-10-11 11:46:28</wp:post_date>
  <wp:post_date_gmt>2013-10-11 11:46:28</wp:post_date_gmt>
  <wp:comment_status>open</wp:comment_status>
  <wp:ping_status>open</wp:ping_status>
  <wp:post_name>flowchart-with-package</wp:post_name>
  <wp:status>inherit</wp:status>
  <wp:post_parent>103</wp:post_parent>
  <wp:menu_order>0</wp:menu_order>
  <wp:post_type>attachment</wp:post_type>
  <wp:post_password/>
  <wp:is_sticky>0</wp:is_sticky>
  <wp:attachment_url>http://lpengineering.files.wordpress.com/2013/10/flowchart-with-package.png</wp:attachment_url>
</item>
<item>
  <title>Assets pipeline</title>
  <link>http://engineering.lonelyplanet.com/?p=120</link>
  <pubDate>Wed, 30 Nov -0001 00:00:00 +0000</pubDate>
  <dc:creator>julienberard</dc:creator>
  <guid isPermaLink="false">http://engineering.lonelyplanet.com/?p=120</guid>
  <description/>
  <content:encoded><![CDATA[]]></content:encoded>
  <excerpt:encoded><![CDATA[]]></excerpt:encoded>
  <wp:post_id>120</wp:post_id>
  <wp:post_date>2013-10-11 11:59:08</wp:post_date>
  <wp:post_date_gmt>0000-00-00 00:00:00</wp:post_date_gmt>
  <wp:comment_status>open</wp:comment_status>
  <wp:ping_status>open</wp:ping_status>
  <wp:post_name/>
  <wp:status>draft</wp:status>
  <wp:post_parent>0</wp:post_parent>
  <wp:menu_order>0</wp:menu_order>
  <wp:post_type>post</wp:post_type>
  <wp:post_password/>
  <wp:is_sticky>0</wp:is_sticky>
  <category domain="category" nicename="uncategorized"><![CDATA[Uncategorized]]></category>
</item>
  </channel>
</rss>
